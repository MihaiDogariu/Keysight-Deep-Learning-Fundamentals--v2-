{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<a href=\"https://colab.research.google.com/github/MihaiDogariu/Keysight-Deep-Learning-Fundamentals--v2-/blob/main/scripts/Unit_7_Fundamental_elements_of_a_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fundamental elements of a neural network\n",
    "This notebook approaches several aspects of neural networks. This particular application aims to forecast wether it will rain or not in the following day, based on the current day's observation. Therefore, this problem can be seen as a classification task."
   ],
   "metadata": {
    "id": "M0GdQZn0KHtI"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SpAc50W-5jqS",
    "ExecuteTime": {
     "end_time": "2025-04-07T21:23:42.050114Z",
     "start_time": "2025-04-07T21:23:38.283691Z"
    }
   },
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RANDOM_SEED = 1 # for reproducibility\n",
    "torch.manual_seed(RANDOM_SEED)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x237e69a0830>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Choosing the data"
   ],
   "metadata": {
    "id": "HkVt2mtcZ963"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Download the [\"Rain in Australia\"](https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package?resource=download) dataset:"
   ],
   "metadata": {
    "id": "7fyidLy7NBS0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!gdown 1D-Ua952YzK95yPCJxzr8SWu7ZJGVROJd"
   ],
   "metadata": {
    "id": "LSiZJEkgM3vI",
    "ExecuteTime": {
     "end_time": "2025-04-07T21:23:49.748351Z",
     "start_time": "2025-04-07T21:23:42.061047Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1D-Ua952YzK95yPCJxzr8SWu7ZJGVROJd\n",
      "To: D:\\Work\\Keysight\\2025\\Programs\\weatherAUS.csv\n",
      "\n",
      "  0%|          | 0.00/14.1M [00:00<?, ?B/s]\n",
      "  7%|7         | 1.05M/14.1M [00:00<00:01, 8.22MB/s]\n",
      " 30%|##9       | 4.19M/14.1M [00:00<00:00, 18.6MB/s]\n",
      " 45%|####4     | 6.29M/14.1M [00:00<00:00, 18.1MB/s]\n",
      " 74%|#######4  | 10.5M/14.1M [00:00<00:00, 25.5MB/s]\n",
      " 93%|#########2| 13.1M/14.1M [00:00<00:00, 25.0MB/s]\n",
      "100%|##########| 14.1M/14.1M [00:00<00:00, 22.8MB/s]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each dataset entry contains 23 fields <-> 23 descriptors/features. We can have a look at its content by calling `pd.DataFrame.head()` on it."
   ],
   "metadata": {
    "id": "J1MGjpHrRjPS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('weatherAUS.csv')\n",
    "print(df.shape)\n",
    "print(list(df.columns))\n",
    "df.head(5)"
   ],
   "metadata": {
    "id": "yVhUHfqIRCLA",
    "ExecuteTime": {
     "end_time": "2025-04-07T21:23:50.908363Z",
     "start_time": "2025-04-07T21:23:50.160861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145460, 23)\n",
      "['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine', 'WindGustDir', 'WindGustSpeed', 'WindDir9am', 'WindDir3pm', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm', 'RainToday', 'RainTomorrow']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
       "0           W           44.0          W  ...        71.0         22.0   \n",
       "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
       "2         WSW           46.0          W  ...        38.0         30.0   \n",
       "3          NE           24.0         SE  ...        45.0         16.0   \n",
       "4           W           41.0        ENE  ...        82.0         33.0   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
       "0       1007.7       1007.1       8.0       NaN     16.9     21.8         No   \n",
       "1       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
       "2       1007.6       1008.7       NaN       2.0     21.0     23.2         No   \n",
       "3       1017.6       1012.8       NaN       NaN     18.1     26.5         No   \n",
       "4       1010.8       1006.0       7.0       8.0     17.8     29.7         No   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "\n",
       "[5 rows x 23 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "##2. Data pre-processing"
   ],
   "metadata": {
    "id": "DGZT9RZqaVmI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# The dataset contains a large set of attributes, but we are not interested in all of them\n",
    "# Let us make a list with the interesting attributes only\n",
    "keep = ['MinTemp', 'MaxTemp', 'Rainfall', 'Humidity3pm', 'Pressure9am', 'RainToday', 'RainTomorrow']\n",
    "\n",
    "# We keep only the attributes that belong to the above list\n",
    "df_keep = df[keep]\n",
    "\n",
    "# Replace literal strings such as yes/no with numerical values 1/0\n",
    "df_keep['RainToday'].replace({'No': 0, 'Yes': 1}, inplace = True)\n",
    "df_keep['RainTomorrow'].replace({'No': 0, 'Yes': 1}, inplace = True)\n",
    "\n",
    "# The dataset also contains NaN values, which must be dealt with. Simplest solution is to eliminate them, altogether.\n",
    "df_keep = df_keep.dropna(how='any')\n",
    "df_keep.head(5)"
   ],
   "metadata": {
    "id": "QmmkMfi9Ry7x",
    "ExecuteTime": {
     "end_time": "2025-04-07T21:23:51.210474Z",
     "start_time": "2025-04-07T21:23:51.019067Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihai\\AppData\\Local\\Temp\\ipykernel_3772\\3180366349.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_keep['RainToday'].replace({'No': 0, 'Yes': 1}, inplace = True)\n",
      "C:\\Users\\mihai\\AppData\\Local\\Temp\\ipykernel_3772\\3180366349.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_keep['RainToday'].replace({'No': 0, 'Yes': 1}, inplace = True)\n",
      "C:\\Users\\mihai\\AppData\\Local\\Temp\\ipykernel_3772\\3180366349.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_keep['RainToday'].replace({'No': 0, 'Yes': 1}, inplace = True)\n",
      "C:\\Users\\mihai\\AppData\\Local\\Temp\\ipykernel_3772\\3180366349.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_keep['RainTomorrow'].replace({'No': 0, 'Yes': 1}, inplace = True)\n",
      "C:\\Users\\mihai\\AppData\\Local\\Temp\\ipykernel_3772\\3180366349.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_keep['RainTomorrow'].replace({'No': 0, 'Yes': 1}, inplace = True)\n",
      "C:\\Users\\mihai\\AppData\\Local\\Temp\\ipykernel_3772\\3180366349.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_keep['RainTomorrow'].replace({'No': 0, 'Yes': 1}, inplace = True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   MinTemp  MaxTemp  Rainfall  Humidity3pm  Pressure9am  RainToday  \\\n",
       "0     13.4     22.9       0.6         22.0       1007.7        0.0   \n",
       "1      7.4     25.1       0.0         25.0       1010.6        0.0   \n",
       "2     12.9     25.7       0.0         30.0       1007.6        0.0   \n",
       "3      9.2     28.0       0.0         16.0       1017.6        0.0   \n",
       "4     17.5     32.3       1.0         33.0       1010.8        0.0   \n",
       "\n",
       "   RainTomorrow  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see the number of rainy and not rainy days"
   ],
   "metadata": {
    "id": "WotMmiqX3lOS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"No. of days when it did not rain: \", df_keep['RainTomorrow'].value_counts()[0])\n",
    "print(\"No. of days when it rained: \", df_keep['RainTomorrow'].value_counts()[1])\n",
    "\n",
    "# Display these values as a ratio of the entire dataset\n",
    "df_keep['RainTomorrow'].value_counts() / df_keep.shape[0]"
   ],
   "metadata": {
    "id": "gFkw5Asua3qI",
    "ExecuteTime": {
     "end_time": "2025-04-07T21:23:51.321446Z",
     "start_time": "2025-04-07T21:23:51.289680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of days when it did not rain:  96989\n",
      "No. of days when it rained:  27550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RainTomorrow\n",
       "0.0    0.778784\n",
       "1.0    0.221216\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    " We can observe that the dataset is not balanced, having 3.5 times more days when it did not rain as compared to the number of days when it rained."
   ],
   "metadata": {
    "id": "4rNlvHtYbdS4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# We can balance the dataset by under-sampling the over-represented subset\n",
    "under_sample = True\n",
    "\n",
    "if under_sample:\n",
    "  rain = df_keep[df_keep['RainTomorrow']==1] # select only the entries where rain was present\n",
    "  no_rain = df_keep[df_keep['RainTomorrow']==0] # select only the entries where rain was not present\n",
    "  no_rain = no_rain.sample(n=len(rain)) # pick len(rain) samples randomly from no_rain\n",
    "  df_keep = pd.concat([rain,no_rain],axis=0) # concatenate the 2 subsets and obtain a balanced dataset\n",
    "\n",
    "print(\"No. of days when it did not rain: \", df_keep['RainTomorrow'].value_counts()[0])\n",
    "print(\"No. of days when it rained: \", df_keep['RainTomorrow'].value_counts()[1])"
   ],
   "metadata": {
    "id": "bFpt29hqYQvo",
    "ExecuteTime": {
     "end_time": "2025-04-07T21:23:51.640769Z",
     "start_time": "2025-04-07T21:23:51.592626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of days when it did not rain:  27550\n",
      "No. of days when it rained:  27550\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "The newly formed dataset will be now split into inputs and outputs. The outputs represent the labels associated with the input data. In this context, the labels are the decision rain/no rain."
   ],
   "metadata": {
    "id": "4iojMJGURQbk"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "x = df_keep[keep[:-1]]\n",
    "y = df_keep[keep[-1]]"
   ],
   "metadata": {
    "id": "e8RaZ8MJhLcG",
    "ExecuteTime": {
     "end_time": "2025-04-07T21:23:51.735679Z",
     "start_time": "2025-04-07T21:23:51.708215Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "We split the dataset after the 70-15-15 train-val-test rule. The function `train_test_split` will split the data in only two subsets. Therefore, we must call it twice:\n",
    "1.   Divide the original dataset into `train_val` and `test`;\n",
    "2.   Divide `train_val` into `train` and `val`.\n",
    "\n"
   ],
   "metadata": {
    "id": "EuavNnT7ihHR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# Divide the original dataset into 'train_val' and 'test':\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(x, y, test_size=test_ratio)\n",
    "print('train_val subset dimensions: {}\\ttest subset dimensions: {}'.format(x_train_val.shape, x_test.shape))\n",
    "\n",
    "# Divide 'train_val' into 'train' and 'val'\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=val_ratio/(val_ratio + train_ratio))\n",
    "print('train subset dimensions: {}\\tval subset dimensions: {}\\ttest subset dimensions:{}'.format(x_train.shape, x_val.shape, x_test.shape))"
   ],
   "metadata": {
    "id": "yp9gwFQfiZUz",
    "ExecuteTime": {
     "end_time": "2025-04-07T21:23:51.815577Z",
     "start_time": "2025-04-07T21:23:51.767407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_val subset dimensions: (46835, 6)\ttest subset dimensions: (8265, 6)\n",
      "train subset dimensions: (38570, 6)\tval subset dimensions: (8265, 6)\ttest subset dimensions:(8265, 6)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "We switch the data from `pandas.DataFrame` format to `Tensor` format in order for them to be processed by PyTorch."
   ],
   "metadata": {
    "id": "Zpl4yrYqTFJ0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "x_train = torch.from_numpy(x_train.to_numpy()).float()\n",
    "y_train = torch.squeeze(torch.from_numpy(y_train.to_numpy()).float())\n",
    "\n",
    "x_val = torch.from_numpy(x_val.to_numpy()).float()\n",
    "y_val = torch.squeeze(torch.from_numpy(y_val.to_numpy()).float())\n",
    "\n",
    "x_test = torch.from_numpy(x_test.to_numpy()).float()\n",
    "y_test = torch.squeeze(torch.from_numpy(y_test.to_numpy()).float())\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ],
   "metadata": {
    "id": "k65jnrT5l-qj",
    "ExecuteTime": {
     "end_time": "2025-04-07T21:23:51.910509Z",
     "start_time": "2025-04-07T21:23:51.879168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([38570, 6]) torch.Size([38570])\n",
      "torch.Size([8265, 6]) torch.Size([8265])\n",
      "torch.Size([8265, 6]) torch.Size([8265])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "##3. Training and validating the model"
   ],
   "metadata": {
    "id": "6wHvU5kumUEo"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first step is creating the neural network model. In PyTorch, models are usually created as a class that inherits the `torch.nn.Module` class. The model must define 2 functions:\n",
    "\n",
    "\n",
    "1.   `__init__()` - sets the general component structure of the network;\n",
    "2.   `forward()` - sets the behaviour for the feed-forward.\n",
    "\n"
   ],
   "metadata": {
    "id": "9AU-WGJ1XsaU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Net(torch.nn.Module):\n",
    "\n",
    "  def __init__(self, n_features): # the n_features argument is used to establish the dimension of the input layer\n",
    "    super(Net, self).__init__()\n",
    "    self.fc1 = torch.nn.Linear(n_features, 5) # fully connected layer that connects the input to a 5-neuron layer\n",
    "    self.fc2 = torch.nn.Linear(5, 3) # fully connected layer that connects the previous layer to a 3-neuron layer\n",
    "    self.fc3 = torch.nn.Linear(3, 1) # fully connected layer that connects the previous layer to a 1-neuron layer - binary decision\n",
    "\n",
    "  def forward(self, x): # applying the activation function after running each fully connected layer\n",
    "    x = torch.nn.functional.relu(self.fc1(x))\n",
    "    x = torch.nn.functional.relu(self.fc2(x))\n",
    "    return torch.sigmoid(self.fc3(x)) # sigmoid for binary classification"
   ],
   "metadata": {
    "id": "sDpO8Pl8mTqg",
    "ExecuteTime": {
     "end_time": "2025-04-07T21:23:52.005542Z",
     "start_time": "2025-04-07T21:23:51.991750Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initializing the network, the cost function and the optimizier"
   ],
   "metadata": {
    "id": "-lGYLICmZlxl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "net=Net(x_train.shape[1]) # it calls the Net.__init()__ function for model initialization\n",
    "criterion = torch.nn.BCELoss() # Binary Cross-Entropy Loss is the loss function\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01) # Adam optimizer"
   ],
   "metadata": {
    "id": "lQhWLMRDmqg3",
    "ExecuteTime": {
     "end_time": "2025-04-07T21:23:54.366396Z",
     "start_time": "2025-04-07T21:23:52.048750Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading the functions and the data on GPU"
   ],
   "metadata": {
    "id": "521c_blhbCpO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "x_train = x_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "\n",
    "x_val = x_val.to(device)\n",
    "y_val = y_val.to(device)\n",
    "\n",
    "x_test = x_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "net = net.to(device)\n",
    "\n",
    "criterion = criterion.to(device)"
   ],
   "metadata": {
    "id": "frhlNoItnPhs",
    "ExecuteTime": {
     "end_time": "2025-04-07T21:24:12.694015Z",
     "start_time": "2025-04-07T21:24:11.042735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "Auxiliary functions"
   ],
   "metadata": {
    "id": "pv_gU9U_bKJx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Compute accuracy\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "  predicted = y_pred.ge(.5).view(-1)\n",
    "  return (y_true == predicted).sum().float() / len(y_true)\n",
    "\n",
    "# Define a rounding function\n",
    "def round_tensor(t, decimal_places=3):\n",
    "  return round(t.item(), decimal_places)"
   ],
   "metadata": {
    "id": "q1iy47cbnZSO",
    "ExecuteTime": {
     "end_time": "2025-04-07T21:24:16.882249Z",
     "start_time": "2025-04-07T21:24:16.874386Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model training"
   ],
   "metadata": {
    "id": "PE9K7L1Sb7jc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for epoch in range(1000):\n",
    "\n",
    "    y_pred = net(x_train) # forward propagation\n",
    "    y_pred = torch.squeeze(y_pred)\n",
    "    train_loss = criterion(y_pred, y_train) # compute cost function\n",
    "\n",
    "    if epoch % 100 == 0: # perform validation once in a while\n",
    "      train_acc = calculate_accuracy(y_train, y_pred) # compute train accuracy\n",
    "\n",
    "      y_val_pred = net(x_val) # forward propagation\n",
    "      y_pred = torch.squeeze(y_pred)\n",
    "      y_val_pred = torch.squeeze(y_val_pred)\n",
    "\n",
    "      val_loss = criterion(y_val_pred, y_val) # compute cost function\n",
    "\n",
    "      val_acc = calculate_accuracy(y_val, y_val_pred) # compute validation accuracy\n",
    "      print(\"epoch {}\\nTrain set - loss: {}, accuracy: {}\\nTest  set - loss: {}, accuracy: {}\"\n",
    "            .format(epoch,\n",
    "                    round_tensor(train_loss), round_tensor(train_acc),\n",
    "                    round_tensor(val_loss), round_tensor(val_acc)))\n",
    "\n",
    "    optimizer.zero_grad() # erase existing gradients\n",
    "\n",
    "    train_loss.backward() # compute gradients for current iteration\n",
    "\n",
    "    optimizer.step() # perform weights update"
   ],
   "metadata": {
    "id": "_nVIaqzNnvXP"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "After training and optimization on `train` and `val`, we perform another test on the `test` subset."
   ],
   "metadata": {
    "id": "YxDbDq3UvDPC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "classes = ['No rain', 'Raining']\n",
    "\n",
    "y_pred = net(x_test)\n",
    "\n",
    "y_pred = y_pred.ge(.5).view(-1).cpu()\n",
    "y_test = y_test.cpu()\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=classes))"
   ],
   "metadata": {
    "id": "1-FeKlWMontP"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "\n",
    "hmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label');"
   ],
   "metadata": {
    "id": "x3dNfXpmpOhU"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
