{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "V28",
   "authorship_tag": "ABX9TyOCg75Wd2zCsCpQub1rRW1S",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "TPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MihaiDogariu/Keysight-Deep-Learning-Fundamentals--v2-/blob/main/scripts/Unit_9_Image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Image classification\n",
    "This notebook implements the classifc AlexNet architecture for real image classification The demo dataset for this task is CIFAR10. The goal of the project is to design a network which, when presented with a natural image, will assign a label to the said image."
   ],
   "metadata": {
    "id": "cVj8IalH4YlD"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-nROe8lDRLzn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Choose the available system configuration (CPU/GPU)\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# We set the mean and the standard deviation for the normalization process - these are computed channel-wise and only on the training dataset\n",
    "mean=[0.4914, 0.4822, 0.4465]\n",
    "std=[0.2023, 0.1994, 0.2010]\n",
    "normalize = transforms.Normalize(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor\n",
    "\n",
    "unnorm = UnNormalize(mean, std)"
   ],
   "metadata": {
    "id": "ktiGybWF9mNQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 1. Data pre-processing",
   "metadata": {
    "id": "Dj5xxj71llow"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_train_valid_loader(data_dir,\n",
    "                           batch_size,\n",
    "                           augment,\n",
    "                           random_seed,\n",
    "                           normalize,\n",
    "                           valid_size=0.1,\n",
    "                           shuffle=True):\n",
    "\n",
    "    # We define the set of transformations that each input will undergo in the testing phase\n",
    "    valid_transform = transforms.Compose([\n",
    "            transforms.Resize((227,227)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "    ])\n",
    "    if augment: # regularizing techniques\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(0.4),\n",
    "            transforms.Resize((227,227)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "    else:\n",
    "        train_transform = valid_transform\n",
    "\n",
    "    # Being a popular dataset, it can be downloaded directly from torchvivision's model zoo\n",
    "    train_dataset = datasets.CIFAR10(root=data_dir,\n",
    "                                     train=True,\n",
    "                                     download=True,\n",
    "                                     transform=train_transform,\n",
    "                                     )\n",
    "\n",
    "    valid_dataset = datasets.CIFAR10(root=data_dir,\n",
    "                                     train=True,\n",
    "                                     download=True,\n",
    "                                     transform=valid_transform,\n",
    "                                     )\n",
    "\n",
    "    # Select the train-val split\n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    # Create dataloades for the training and validation datasets\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "\n",
    "    return (train_loader, valid_loader)\n",
    "\n",
    "\n",
    "def get_test_loader(data_dir,\n",
    "                    batch_size,\n",
    "                    normalize,\n",
    "                    shuffle=True):\n",
    "\n",
    "    # Similar transforms to train\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((227,227)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    # Download the test dataset\n",
    "    dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=False,\n",
    "        download=True, transform=transform,\n",
    "    )\n",
    "\n",
    "    # Create test data loader\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle\n",
    "    )\n",
    "\n",
    "    return data_loader\n",
    "\n",
    "\n",
    "# Calling the above function\n",
    "train_loader, valid_loader = get_train_valid_loader(\n",
    "    data_dir = './data',\n",
    "    batch_size = 64,\n",
    "    augment = True,\n",
    "    random_seed = 1,\n",
    "    normalize = normalize\n",
    ")\n",
    "\n",
    "test_loader = get_test_loader(\n",
    "    data_dir = './data',\n",
    "    batch_size = 64,\n",
    "    normalize = normalize\n",
    ")"
   ],
   "metadata": {
    "id": "N4sJfy7RVUGr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Defining the model",
   "metadata": {
    "id": "G90-dEwJ45Q2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Official documentation for each layer:\n",
    "- convolutional: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "- fully connected: https://pytorch.org/docs/stable/generated/torch.nn.Linear.html?highlight=linear#torch.nn.Linear\n",
    "- max pooling: https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html?highlight=maxpool#torch.nn.MaxPool2d\n",
    "- ReLU activation: https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html?highlight=relu#torch.nn.ReLU\n",
    "- dropout regularization: https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html?highlight=dropout#torch.nn.Dropout\n",
    "- sequential composition of layers: https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html?highlight=sequential#torch.nn.Sequential"
   ],
   "metadata": {
    "id": "t-s_LREX7Qgy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU())\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(9216, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc2= nn.Sequential(\n",
    "            nn.Linear(4096, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "IzVHcoKlXTko"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Training the model",
   "metadata": {
    "id": "G8FsviED5BHt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Choosing hyperparameters\n",
    "num_classes = 10\n",
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "learning_rate = 0.005\n",
    "\n",
    "# Transferring the model on the device, hopefully GPU\n",
    "model = AlexNet(num_classes).to(device)\n",
    "\n",
    "\n",
    "# Choosing the loss function. Classification means CrossEntropyLoss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Choosing the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)"
   ],
   "metadata": {
    "id": "nxoT-gGLXWKU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Running the training\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train(True)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load tensors on the device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward propagation\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backpropagation and weights update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "    # Running the model on the validation dataset\n",
    "    model.train(False)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "\n",
    "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total))\n"
   ],
   "metadata": {
    "id": "wyvxaODWXY_o"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 4. Testing the model",
   "metadata": {
    "id": "JjNYKyda5E_v"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Running the model on the test set\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        del images, labels, outputs\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))"
   ],
   "metadata": {
    "id": "y9YOC0T0XbyK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "labels = {0:\"airplane\",\n",
    "          1:\"automobile\",\n",
    "          2:\"bird\",\n",
    "          3:\"cat\",\n",
    "          4:\"deer\",\n",
    "          5:\"dog\",\n",
    "          6:\"frog\",\n",
    "          7:\"horse\",\n",
    "          8:\"ship\",\n",
    "          9:\"truck\"}\n"
   ],
   "metadata": {
    "id": "Me50ufAp2FYJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_features, test_labels = next(iter(test_loader)) # extract a batch of images and labels from the test dataset using the data loader\n",
    "img = test_features[0].squeeze()     # extract only the first image from the batch and discard dimensions of value = 1\n",
    "img = unnorm(img)                    # unnormalize the image\n",
    "npimg = img.numpy()                  # transform the tensor into an np array\n",
    "img = np.transpose(npimg, (1, 2, 0)) # transform the images from (3, 227, 227) to (227, 227, 3) for python display\n",
    "label = test_labels[0].item()\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "pred = model(test_features.to(device))[0].cpu().detach().numpy()\n",
    "pred_label = np.argmax(pred)\n",
    "print(f\"True label: {labels[label]}\\t\\t Predicted label: {labels[pred_label]}\")"
   ],
   "metadata": {
    "id": "h1dIYllW_iv8"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
